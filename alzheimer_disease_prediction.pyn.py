# -*- coding: utf-8 -*-
"""Copy of Alzheimer_disease_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZP_fv9spcBTiYUBbYN75TWiNojDL1tCa

Access files stored in your Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')



"""Importing necesary libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
import math
import os
import warnings
warnings.filterwarnings('ignore')

from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix

import keras
from tensorflow import keras
from keras import Sequential
from keras import layers
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

plt.rcParams["figure.figsize"] = (10,6)
plt.rcParams['figure.dpi'] = 300
colors = ["#B6EE56", "#D85F9C", "#EEA756", "#56EEE8"]

"""Set Matplotlib parameters

Prints information about the GPU devices
"""

try:
    if tf.test.gpu_device_name():
        physical_devices = tf.config.experimental.list_physical_devices('GPU')
        print('GPU active! -', physical_devices)
    else:
        print('GPU not active!')
except Exception as e:
    print('An error occurred while checking the GPU:', e)

"""Counting images in each and every folder

"""

import os
import matplotlib.pyplot as plt

class_dist = {}

def image_counter(folder_path):
    print('\033[92m'+f"A search has been initiated within the folder named '{os.path.basename(folder_path)}'."+'\033[0m')
    image_extensions = ['.jpg', '.jpeg', '.png']

    for root, dirs, _ in os.walk(folder_path):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            count = 0

            for filename in os.listdir(dir_path):
                file_ext = os.path.splitext(filename)[1].lower()

                if file_ext in image_extensions:
                    count += 1

            class_dist[dir_name] = count
            if count != 0:
              print(f"There are \033[35m{count}\033[0m images in the {dir_name} folder.")
    print('\033[92m'+"The search has been completed."+'\033[0m')

    keys = list(class_dist.keys())
    values = list(class_dist.values())
    explode = (0.1,)*len(keys)

    labels = [f'{key} ({value} images)' for key, value in zip(keys, values)]

    plt.pie(values, explode=explode, labels=labels, autopct='%1.1f%%',
            shadow=True, startangle=90, textprops={'fontsize': 10, "fontweight" : "bold", "color":"darkblue"}, wedgeprops=
           {'edgecolor':'darkblue'}, labeldistance=1.0)
    plt.title("Distribution of Alzheimer MRI Images", size=12, fontweight="bold")
    plt.show()

PATH = '/content/drive/MyDrive/archive/Dataset'

image_counter(PATH)

data = tf.keras.utils.image_dataset_from_directory(PATH,
                                                batch_size = 32,
                                                image_size=(128, 128),
                                                shuffle=True,
                                                seed=42,)

class_names = data.class_names

def sample_bringer(path, target, num_samples=5):

    class_path = os.path.join(path, target)

    image_files = [image for image in os.listdir(class_path) if image.endswith('.jpg')]

    fig, ax = plt.subplots(1, num_samples, facecolor="gray")
    fig.suptitle(f'{target} Brain MRI Samples', color="yellow",fontsize=16, fontweight='bold', y=0.75)

    for i in range(num_samples):
        image_path = os.path.join(class_path, image_files[i])
        img = mpimg.imread(image_path)

        ax[i].imshow(img)
        ax[i].axis('off')
        ax[i].set_title(f'Sample {i+1}', color="aqua")

    plt.tight_layout()

for target in class_names:
    sample_bringer(PATH, target=target)

"""# Display sample brain MRI images from each class in the specified directory using the sample_bringer function.

"""

alz_dict = {index: img for index, img in enumerate(data.class_names)}

class Process:
    def __init__(self, data):
        self.data = data.map(lambda x, y: (x/255, y))

    def create_new_batch(self):
        self.batch = self.data.as_numpy_iterator().next()
        text = "Min and max pixel values in the batch ->"
        print(text, self.batch[0].min(), "&", self.batch[0].max())

    def show_batch_images(self, number_of_images=5):
        fig, ax = plt.subplots(ncols=number_of_images, figsize=(20,20), facecolor="gray")
        fig.suptitle("Brain MRI (Alzheimer) Samples in the Batch", color="yellow",fontsize=18, fontweight='bold', y=0.6)
        for idx, img in enumerate(self.batch[0][:number_of_images]):
            ax[idx].imshow(img)
            class_no = self.batch[1][idx]
            ax[idx].set_title(alz_dict[class_no], color="aqua")
            ax[idx].set_xticklabels([])
            ax[idx].set_yticklabels([])

    def train_test_val_split(self, train_size, val_size, test_size):

        train = int(len(self.data)*train_size)
        test = int(len(self.data)*test_size)
        val = int(len(self.data)*val_size)

        train_data = self.data.take(train)
        val_data = self.data.skip(train).take(val)
        test_data = self.data.skip(train+val).take(test)

        return train_data, val_data, test_data

# Create an instance of the Process class using the provided image dataset
process = Process(data)

# Create and print a new batch, displaying the range of pixel values
process.create_new_batch()

# Show a batch of brain MRI images with corresponding class labels
process.show_batch_images(number_of_images=5)

train_data, val_data, test_data= process.train_test_val_split(train_size=0.8, val_size=0.1, test_size=0.1)

y_train = tf.concat(list(map(lambda x: x[1], train_data)), axis=0)
class_weight = compute_class_weight('balanced',classes=np.unique(y_train), y=y_train.numpy())
class_weights = dict(zip(np.unique(y_train), class_weight))

def build_model():
    # Create a Sequential model
    model = Sequential()

    # Convolutional Layer 1
    model.add(Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), activation="relu",
                     kernel_initializer='he_normal', input_shape=(128, 128, 3)))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Convolutional Layer 2
    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation="relu",
                     kernel_initializer='he_normal'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Convolutional Layer 3
    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), activation="relu",
                     kernel_initializer='he_normal'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Flatten the output for Dense layers
    model.add(Flatten())

    # Dense Layer 1
    model.add(Dense(128, activation="relu", kernel_initializer='he_normal'))

    # Dense Layer 2
    model.add(Dense(64, activation="relu"))

    # Output Layer
    model.add(Dense(4, activation="softmax"))  # Assuming 4 output classes for Alzheimer's dataset

    # Compile the model
    model.compile(optimizer='adam', loss="sparse_categorical_crossentropy", metrics=['accuracy'])


    # Display the model summary
    model.summary()

    return model

# Create an instance of the model
model = build_model()

""" Define a ModelCheckpoint callback for saving the best model and an
EarlyStopping callback for stopping training based on validation loss.

"""
def checkpoint_callback():

    checkpoint_filepath = '/tmp/checkpoint'

    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,
                           save_weights_only=False,
                           frequency='epoch',
                           monitor='val_accuracy',
                           save_best_only=True,
                           verbose=1)

    return model_checkpoint_callback

def early_stopping(patience):
    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)
    return es_callback


EPOCHS = 4
checkpoint_callback = checkpoint_callback()
early_stopping = early_stopping(patience=5)
callbacks = [checkpoint_callback, early_stopping]

history = model.fit(train_data, epochs = EPOCHS, validation_data = val_data, class_weight = class_weights, callbacks =  callbacks)

# Create a 1x2 subplot for visualizing training history (loss and accuracy)
fig, ax = plt.subplots(1, 2, figsize=(12, 6), facecolor="khaki")

# Plot Loss

ax[0].set_facecolor('palegoldenrod')
ax[0].set_title('Loss', fontweight="bold")
ax[0].set_xlabel("Epoch", size=14)
ax[0].plot(history.epoch, history.history["loss"], label="Train Loss", color="navy")
ax[0].plot(history.epoch, history.history["val_loss"], label="Validation Loss", color="crimson", linestyle="dashed")
ax[0].legend()

# Plot Accuracy
ax[1].set_facecolor('palegoldenrod')
ax[1].set_title('Accuracy', fontweight="bold")
ax[1].set_xlabel("Epoch", size=14)
ax[1].plot(history.epoch, history.history["accuracy"], label="Train Acc.", color="navy")
ax[1].plot(history.epoch, history.history["val_accuracy"], label="Validation Acc.", color="crimson", linestyle="dashed")
ax[1].legend()

model.evaluate(test_data)

predictions = []
labels = []

for X, y in test_data.as_numpy_iterator():
    y_pred = model.predict(X, verbose=0)
    y_prediction = np.argmax(y_pred, axis=1)
    predictions.extend(y_prediction)
    labels.extend(y)


predictions = np.array(predictions)
labels = np.array(labels)

print(classification_report(labels, predictions, target_names=class_names))

cm = confusion_matrix(labels, predictions)
cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)
cm_df
plt.figure(figsize=(10,6), dpi=300)
sns.heatmap(cm_df, annot=True, cmap="Greys", fmt=".1f")
plt.title("Confusion Matrix", fontweight="bold")
plt.xlabel("Predicted", fontweight="bold")
plt.ylabel("True", fontweight="bold")

def random_mri_prob_bringer(image_number=0):
    pred = None  # Initialize pred outside the loop

    for images, _ in test_data.skip(5).take(1):
        image = images[image_number]
        pred = model.predict(tf.expand_dims(image, 0))[0]

    # Check if pred is not None before proceeding
    if pred is not None:
        probs = list(tf.nn.softmax(pred).numpy())
        probs_dict = dict(zip(class_dist.keys(), probs))

        keys = list(probs_dict.keys())
        values = list(probs_dict.values())

        fig, (ax1, ax2) = plt.subplots(1, 2, facecolor='black')
        plt.subplots_adjust(wspace=0.4)
        ax1.imshow(image)
        ax1.set_title('Brain MRI', color="yellow", fontweight="bold", fontsize=16)

        edges = ['left', 'bottom', 'right', 'top']
        edge_color = "greenyellow"
        edge_width = 3
        for edge in edges:
            ax1.spines[edge].set_linewidth(edge_width)
            ax1.spines[edge].set_edgecolor(edge_color)

        plt.gca().axes.yaxis.set_ticklabels([])
        plt.gca().axes.xaxis.set_ticklabels([])

        wedges, labels, autopct = ax2.pie(values, labels=keys,  autopct='%1.1f%%',
            shadow=True, startangle=90, colors=colors, textprops={'fontsize': 8, "fontweight":"bold", "color":"white"},  wedgeprops=
           {'edgecolor':'black'} , labeldistance=1.15)

        for autotext in autopct:
            autotext.set_color('black')

        ax2.set_title('Alzheimer Probabilities', color="yellow", fontweight="bold", fontsize=16)

# Generate a random image number
rand_img_no = np.random.randint(1, 32)
random_mri_prob_bringer(image_number=rand_img_no)

plt.figure(figsize=(20, 20), facecolor="gray")
for images, labels in test_data.take(1):
    for i in range(25):
        ax = plt.subplot(5, 5, i + 1)
        plt.imshow(images[i])
        predictions = model.predict(tf.expand_dims(images[i], 0), verbose=0)
        score = tf.nn.softmax(predictions[0])
        if(class_names[labels[i]]==class_names[np.argmax(score)]):
            plt.title("Actual: "+class_names[labels[i]], color="aqua", fontweight="bold", fontsize=10)
            plt.ylabel("Predicted: "+class_names[np.argmax(score)], color="springgreen", fontweight="bold", fontsize=10)
            ok_text = plt.text(2, 10, "OK \u2714", color="springgreen", fontsize=14)
            ok_text.set_bbox(dict(facecolor='lime', alpha=0.5))

        else:
            plt.title("Actual: "+class_names[labels[i]], color="aqua", fontweight="bold", fontsize=10)
            plt.ylabel("Predicted: "+class_names[np.argmax(score)], color="maroon", fontweight="bold", fontsize=10)
            nok_text = plt.text(2, 10, "NOK \u2718", color="red", fontsize=14)
            nok_text.set_bbox(dict(facecolor='maroon', alpha=0.5))
        plt.gca().axes.yaxis.set_ticklabels([])
        plt.gca().axes.xaxis.set_ticklabels([])

import cv2
from tensorflow.keras.preprocessing import image

def predict_single_image(image_path, model):
    # Load and preprocess the image
    img = image.load_img(image_path, target_size=(128, 128))  # Assuming input size is (128, 128)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Normalize pixel values

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)

    return predicted_class

# Example usage:
image_path = "/content/drive/MyDrive/archive/Dataset/Mild_Demented/mild.jpg"
predicted_class = predict_single_image(image_path, model)
print("Predicted class:", class_names[predicted_class])

image_path = "/content/drive/MyDrive/archive/Dataset/Moderate_Demented/moderate_10.jpg"
predicted_class = predict_single_image(image_path, model)
print("Predicted class:", class_names[predicted_class])

!pip install flask flask-ngrok

from flask import Flask, render_template, request
from flask_ngrok import run_with_ngrok
import numpy as np
from PIL import Image
import io

app = Flask(__name__)
run_with_ngrok(app)

# Define your model and other necessary variables here

@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        # Get the uploaded file
        file = request.files['file']
        if file:
            # Process the image
            img = Image.open(io.BytesIO(file.read()))
            img = img.resize((128, 128))
            img_array = np.array(img) / 255.0
            img_array = np.expand_dims(img_array, axis=0)

            # Make predictions using your model
            predicted_class = predict_single_image(img_array)  # Implement this function

            # Return the predicted class
            return render_template('result.html', predicted_class=predicted_class)

    return render_template('index.html')

if __name__ == '__main__':
    app.run()

from IPython.display import HTML
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Classification</title>
</head>
<body>
    <h1>Upload an Image</h1>
    <form method="post" enctype="multipart/form-data">
        <input type="file" name="file">
        <button type="submit">Upload</button>
    </form>
</body>
</html>

if __name__ == '__main__':
    app.run()
